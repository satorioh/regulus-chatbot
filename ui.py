import streamlit as st
from llm import init_agent

MAX_CONTEXT = 1000

st.set_page_config(
    page_title="Regulus Chatbot",
    page_icon=":robot:",
    menu_items={"about": '''
                Author: Robin.Wang

                Model: ChatGPT-3.5-tubo
                '''}
)

st.title("Regulus ChatbotğŸ‘‹")
history_dom = st.empty()
question_dom = st.markdown(
    ">  å›ç­”ç”± AI ç”Ÿæˆï¼Œä¸ä¿è¯å‡†ç¡®ç‡ï¼Œä»…ä¾›å‚è€ƒå­¦ä¹ ï¼"
)
answer_dom = st.empty()
st.write("")


@st.cache_resource
def get_agent():
    agent = init_agent()
    return agent


agent = get_agent()


def display_history(history=None):
    if history != None:
        text = ""
        for item in history:
            text += f"{item.content}\n\n"
            history_dom.markdown(text)


def predict(input):
    try:
        return agent.run(input=input)
    except Exception as e:
        return "å‡ºé”™äº†ï¼Œè¯·ç¨åå†è¯•"


with st.form("form", True):
    # create a prompt text for the text generation
    user_input = st.text_area(label=":thinking_face: å’¨è¯¢ç‚¹ä»€ä¹ˆï¼Ÿ",
                              height=100,
                              max_chars=MAX_CONTEXT,
                              placeholder="æ”¯æŒä½¿ç”¨ Markdown æ ¼å¼ä¹¦å†™")
    col1, col2 = st.columns([1, 1])
    with col1:
        btn_send = st.form_submit_button(
            "å‘é€", use_container_width=True, type="primary")
    with col2:
        btn_clear = st.form_submit_button("æ¸…é™¤å†å²è®°å½•", use_container_width=True)

    if btn_send and user_input != "":
        display_history(agent.memory.buffer)
        question_dom.markdown(
            ":face_with_cowboy_hat:\n\n{}\n\n---\n".format(user_input))
        answer = predict(user_input)
        print(f"å›ç­”ï¼š{answer}", flush=True)
        answer_dom.markdown(answer)

    if btn_clear:
        history_dom.empty()
        agent.memory.clear()
