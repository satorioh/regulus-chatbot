import streamlit as st
import os
from langchain.chat_models import ChatOpenAI

MAX_CONTEXT = 1000
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_BASE = os.getenv("BASE_URL")
MODEL_NAME = "gpt-3.5-turbo"

st.set_page_config(
    page_title="Regulus Chatbot",
    page_icon=":robot:",
    menu_items={"about": '''
                Author: Robin.Wang

                Model: ChatGPT-3.5-tubo
                '''}
)

st.title("Regulus ChatbotğŸ‘‹")
history_dom = st.empty()
question_dom = st.markdown(
    ">  å›ç­”ç”± AI ç”Ÿæˆï¼Œä¸ä¿è¯å‡†ç¡®ç‡ï¼Œä»…ä¾›å‚è€ƒå­¦ä¹ ï¼"
)
answer_dom = st.empty()
st.write("")


@st.cache_resource
def get_chat():
    chat = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        openai_api_base=OPENAI_API_BASE,
        temperature=0,
        model_name=MODEL_NAME
    )
    return chat


chat = get_chat()


def predict(input):
    return chat.predict(input)


with st.form("form", True):
    # create a prompt text for the text generation
    user_input = st.text_area(label=":thinking_face: å’¨è¯¢ç‚¹ä»€ä¹ˆï¼Ÿ",
                              height=100,
                              max_chars=MAX_CONTEXT,
                              placeholder="æ”¯æŒä½¿ç”¨ Markdown æ ¼å¼ä¹¦å†™")
    col1, col2 = st.columns([1, 1])
    with col1:
        btn_send = st.form_submit_button(
            "å‘é€", use_container_width=True, type="primary")
    with col2:
        btn_clear = st.form_submit_button("æ¸…é™¤å†å²è®°å½•", use_container_width=True)

    if btn_send and user_input != "":
        answer = predict(user_input)
        print(f"å›ç­”ï¼š{answer}", flush=True)
        answer_dom.markdown(answer)
